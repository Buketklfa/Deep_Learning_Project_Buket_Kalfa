{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Klasik kütüphaneler.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n# TensorFlow\nimport tensorflow as tf\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"fish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset' \nclasses = [i for i in os.listdir(fish_dir) if '.' not in i]                    \nclasses","metadata":{"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['Hourse Mackerel',\n 'Black Sea Sprat',\n 'Sea Bass',\n 'Red Mullet',\n 'Trout',\n 'Striped Red Mullet',\n 'Shrimp',\n 'Gilt-Head Bream',\n 'Red Sea Bream']"},"metadata":{}}]},{"cell_type":"markdown","source":"**Veri Önişleme Süreci**","metadata":{}},{"cell_type":"code","source":"label = []\npath = []\n\nfish_dir = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\nfor dir_name, _,filenames in os.walk(fish_dir):                    \n    for filename in filenames:                                 \n        if os.path.splitext(filename)[-1]=='.png':               # If filename contains .png\n            if dir_name.split()[-1]!='GT':                       # If directory doesn't contain GT\n                label.append(os.path.split(dir_name)[-1])         # Append the directory name to label \n                path.append(os.path.join(dir_name,filename))     # Append all the png files to path of that directory\n\ndata = pd.DataFrame(columns=['path','label'])\ndata['path']=path\ndata['label']=label\n                \n\n    # İlk birkaç satırı inceleyelim\nprint(data.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:25:29.606949Z","iopub.execute_input":"2024-10-24T19:25:29.608021Z","iopub.status.idle":"2024-10-24T19:25:29.742415Z","shell.execute_reply.started":"2024-10-24T19:25:29.607975Z","shell.execute_reply":"2024-10-24T19:25:29.740759Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"                                                path            label\n0  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n1  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n2  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n3  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n4  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n","output_type":"stream"}]},{"cell_type":"markdown","source":"veri setinin içeriği","metadata":{}},{"cell_type":"code","source":"data.head() ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:26:42.496431Z","iopub.execute_input":"2024-10-24T19:26:42.496914Z","iopub.status.idle":"2024-10-24T19:26:42.512543Z","shell.execute_reply.started":"2024-10-24T19:26:42.496871Z","shell.execute_reply":"2024-10-24T19:26:42.511031Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                                path            label\n0  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n1  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n2  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n3  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel\n4  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Hourse Mackerel","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Hourse Mackerel</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Hourse Mackerel</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Hourse Mackerel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Hourse Mackerel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Hourse Mackerel</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:26:53.318878Z","iopub.execute_input":"2024-10-24T19:26:53.319775Z","iopub.status.idle":"2024-10-24T19:26:53.331009Z","shell.execute_reply.started":"2024-10-24T19:26:53.319725Z","shell.execute_reply":"2024-10-24T19:26:53.329553Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                                   path          label\n8995  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Red Sea Bream\n8996  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Red Sea Bream\n8997  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Red Sea Bream\n8998  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Red Sea Bream\n8999  /kaggle/input/a-large-scale-fish-dataset/Fish_...  Red Sea Bream","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8995</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Red Sea Bream</td>\n    </tr>\n    <tr>\n      <th>8996</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Red Sea Bream</td>\n    </tr>\n    <tr>\n      <th>8997</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Red Sea Bream</td>\n    </tr>\n    <tr>\n      <th>8998</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Red Sea Bream</td>\n    </tr>\n    <tr>\n      <th>8999</th>\n      <td>/kaggle/input/a-large-scale-fish-dataset/Fish_...</td>\n      <td>Red Sea Bream</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:27:21.368388Z","iopub.execute_input":"2024-10-24T19:27:21.368911Z","iopub.status.idle":"2024-10-24T19:27:21.386790Z","shell.execute_reply.started":"2024-10-24T19:27:21.368850Z","shell.execute_reply":"2024-10-24T19:27:21.385588Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"label\nHourse Mackerel       1000\nBlack Sea Sprat       1000\nSea Bass              1000\nRed Mullet            1000\nTrout                 1000\nStriped Red Mullet    1000\nShrimp                1000\nGilt-Head Bream       1000\nRed Sea Bream         1000\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 32\nimg_height = 224\nimg_width = 224","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:28:54.547645Z","iopub.execute_input":"2024-10-24T19:28:54.548638Z","iopub.status.idle":"2024-10-24T19:28:54.553262Z","shell.execute_reply.started":"2024-10-24T19:28:54.548594Z","shell.execute_reply":"2024-10-24T19:28:54.552168Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Print the number of samples\nprint(f\"X_train: {len(X_train)}\")\nprint(f\"X_test: {len(X_test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:30:19.121285Z","iopub.execute_input":"2024-10-24T19:30:19.121779Z","iopub.status.idle":"2024-10-24T19:30:19.128287Z","shell.execute_reply.started":"2024-10-24T19:30:19.121735Z","shell.execute_reply":"2024-10-24T19:30:19.127008Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"X_train: 14400\nX_test: 3600\n","output_type":"stream"}]},{"cell_type":"code","source":"# Veri setinin sayısını kontrol et\nprint(data['label'].value_counts())\n\n# Hiperparametreler\nbatch_size = 32\nimg_height = 224\nimg_width = 224\nepochs = 20  # Epoch sayısını artırdık\n\n# Veri artırma ve validation split ile veri jeneratörlerini ayarla\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2  # %20 veriyi validasyon için ayır\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=data,\n    x_col='path',\n    y_col='label',\n    target_size=(img_height, img_width),\n    class_mode='categorical',\n    batch_size=batch_size,\n    subset='training'\n)\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n    dataframe=data,\n    x_col='path',\n    y_col='label',\n    target_size=(img_height, img_width),\n    class_mode='categorical',\n    batch_size=batch_size,\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T20:05:15.210590Z","iopub.execute_input":"2024-10-24T20:05:15.211167Z","iopub.status.idle":"2024-10-24T20:05:19.334881Z","shell.execute_reply.started":"2024-10-24T20:05:15.211121Z","shell.execute_reply":"2024-10-24T20:05:19.333701Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"label\nHourse Mackerel       1000\nBlack Sea Sprat       1000\nSea Bass              1000\nRed Mullet            1000\nTrout                 1000\nStriped Red Mullet    1000\nShrimp                1000\nGilt-Head Bream       1000\nRed Sea Bream         1000\nName: count, dtype: int64\nFound 7200 validated image filenames belonging to 9 classes.\nFound 1800 validated image filenames belonging to 9 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**CNN**","metadata":{}},{"cell_type":"code","source":"# CNN Modelini oluştur\nmodel_cnn = keras.Sequential([\n    layers.InputLayer(input_shape=(img_height, img_width, 3)),\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(256, (3, 3), activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dropout(0.5),  # Dropout katmanı ekle\n    layers.Dense(128, activation='relu'),\n    layers.Dense(len(train_generator.class_indices), activation='softmax')])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T20:06:13.724239Z","iopub.execute_input":"2024-10-24T20:06:13.724662Z","iopub.status.idle":"2024-10-24T20:06:13.814250Z","shell.execute_reply.started":"2024-10-24T20:06:13.724626Z","shell.execute_reply":"2024-10-24T20:06:13.813101Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Modeli derle\nmodel_cnn.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-10-24T20:06:23.101988Z","iopub.execute_input":"2024-10-24T20:06:23.102446Z","iopub.status.idle":"2024-10-24T20:06:23.114906Z","shell.execute_reply.started":"2024-10-24T20:06:23.102404Z","shell.execute_reply":"2024-10-24T20:06:23.113567Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Modeli eğit\nwith tf.device('/GPU:0'):\n    # Öğrenme oranı ayarlayıcıyı ekle\n    lr_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n\n    history = model_cnn.fit(\n        train_generator,\n        epochs=epochs,\n        validation_data=validation_generator,\n        callbacks=[lr_reduction]\n    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeli değerlendir\nloss, accuracy = model_cnn.evaluate(validation_generator)\nprint(f'Validation loss: {loss}')\nprint(f'Validation accuracy: {accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}